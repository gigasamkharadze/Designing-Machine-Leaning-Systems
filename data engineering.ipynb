{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Sources\n",
    "\n",
    "### User input data\n",
    "User input can be text, images, videos, uploaded files, etc. If it’s even remotely possible for users to\n",
    "input **wrong data**, they are going to do it. As a result, user input data can be easily malformatted.\n",
    "- Text: misspelled words, wrong grammar, long text, short text, etc.\n",
    "- Input value type mismatch: a user enters a string where a number is expected.\n",
    "- Files: wrong file format, wrong file encoding, etc.\n",
    "\n",
    "### System generated data\n",
    "System generated data is data that is generated by the system itself.\n",
    "- Logs: memory usage, number of instances, etc. The main purpose of logs is to help in debugging and monitoring.\n",
    "- Users behavior: clicks, views, etc. This data is used to improve the user experience.\n",
    "- And many more."
   ],
   "id": "d401d4acda90f299"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Formats\n",
    "Storing your data isn’t always straightforward and, for some cases, can be costly. It’s important to think about how the data will be used in the future so that the format you use will make sense. Here are some common data formats used in practice:\n",
    "\n",
    "![data formats](./screenshots/data-formats.png)\n",
    "\n",
    "## Row-Major Versus Column-Major Format\n",
    "- **Row-major format**: In row-major format, the elements of a row are stored in contiguous memory locations. For example, CSV files are row-major format.\n",
    "- **Column-major format**: In column-major format, the elements of a column are stored in contiguous memory locations. For example, Parquet files are column-major format.\n",
    "\n",
    "***NumPy Versus pandas***: NumPy is row-major format, while pandas is column-major format."
   ],
   "id": "58cac989accbf4dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:30:56.696344Z",
     "start_time": "2025-02-05T17:30:56.671898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    f'Column_{i}': range(i * 1000 + 1, (i + 1) * 1000 + 1) for i in range(20)\n",
    "})\n",
    "\n",
    "start = time.time()\n",
    "for column in df.columns:\n",
    "    for item in df[column]:\n",
    "        pass\n",
    "print(f'column: {time.time() - start}')\n",
    "\n",
    "start = time.time()\n",
    "n_rows = len(df)\n",
    "for i in range(n_rows):\n",
    "    for item in df.iloc[i]:\n",
    "        pass\n",
    "print(f'row: {time.time() - start}')"
   ],
   "id": "a3c7900a6499d63f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: 0.0035429000854492188\n",
      "row: 0.011175870895385742\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text Versus Binary Format\n",
    "- **Text format**: Text format is human-readable and human-editable. It’s easy to understand and debug. However, it’s less efficient in terms of storage and processing.\n",
    "- **Binary format**: Binary format is not human-readable or human-editable. The file contains only 0s and 1s.\n",
    "\n",
    "Consider that you want to store the number 1000000. If you store it in a text file, it’ll require 7 characters, and if each character is 1 byte, it’ll require 7 bytes. If you store it in a binary file as int32, it’ll take only 32 bits or 4 bytes."
   ],
   "id": "1ef3605446179948"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Models\n",
    "Data models describe how the data is represented. There are two main data models:\n",
    "- **Relational model**: In the relational model, data is stored in tables. Each table has rows and columns. The tables are related to each other by keys.\n",
    "- **Non-relational model**: In the non-relational model, data is stored in a non-tabular format. There are different types of non-relational databases, such as document-based, key-value, wide-column, and graph databases.\n",
    "    - **Document-based databases**: Collection of documents: often a single continuous string, encoded as JSON, XML, or a binary format like BSON. All documents in the database are assumed to be decoded in the same format.\n",
    "    - **Graph databases**: Collection of nodes and edges. Each node represents an entity and each edge represents a connection or relationship between two nodes.\n",
    "\n",
    "\n",
    "### Structured data versus Unstructured data\n",
    "Structured data follows a predefined data model, also known as a data schema. The predefined structure makes your\n",
    "data easier to analyze, query, and organize.\n",
    "\n",
    "\n",
    "### Transactional and Analytical Processing\n",
    "\n",
    "- ***OLTP (Online Transaction Processing)***: Because these transactions often involve users, they need to be processed fast so that they don’t keep users waiting. The processing system needs to be available any time a\n",
    "user wants to make a transaction. They are characterized by ACID properties:\n",
    "    - Atomicity: All parts of a transaction must be completed successfully, or the transaction is aborted.\n",
    "    - Consistency: The database must be in a consistent state before and after the transaction.\n",
    "    - Isolation: Transactions should be isolated from each other until they are completed.\n",
    "    - Durability: Once a transaction is completed, it should be permanent and not undone.\n",
    "\n",
    "- ***OLAP (Online Analytical Processing)***: OLAP is used for complex queries that involve aggregations. These queries are often used for reporting and business intelligence. They are characterized by CAP properties:\n",
    "    - Consistency: All nodes see the same data at the same time.\n",
    "    - Availability: The system is always available.\n",
    "    - Partition tolerance: The system continues to operate despite network partitions.\n"
   ],
   "id": "87060d15ab15c5cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ETL (Extract -> Transform -> Load)\n",
    "In the early days of the relational data model, data was mostly structured. When data is extracted from different sources, it’s first transformed into the desired format before being loaded into the target destination such as a database or a data warehouse.\n",
    "\n",
    "![ETL](./screenshots/etl.png)\n",
    "\n",
    "Finding it difficult to keep data structured, some companies had this idea: “Why not just store all data in a data lake so we don’t have to deal with schema changes? Whichever application needs data can just pull out raw data from there and process it.\n",
    "\n",
    "# ELT (Extract -> Load -> Transform)\n",
    "In the ELT process, data is first loaded into the target destination and then transformed. This is done because the data is already in the desired format and can be transformed as needed. This approach is more flexible and scalable than the ETL approach."
   ],
   "id": "f23d31bb99cd6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data Warehouse\n",
    "A data warehouse is a centralized repository that stores structured and unstructured data from one or more sources. It’s a system used for reporting and data analysis. A data warehouse is a type of database that is specifically designed for query and analysis rather than transaction processing.\n",
    "\n",
    "### Data Lake\n",
    "A data lake is a storage repository that holds a vast amount of raw data in its native format until it’s needed. Data lakes are often used to store unstructured data, such as web server logs, IoT data, images, and videos. Data lakes are often used for data exploration and analysis."
   ],
   "id": "79a7e17594aeacc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DataFlow\n",
    "Data flow is the movement of data between processes:\n",
    "- Through databases\n",
    "- APIs (request-driven)\n",
    "- Real time transport (like Apache Kafka)\n",
    "\n",
    "For example, Driver management service predicts the demand for drivers in a specific area, Ride management service - how many rides will be requested. Price optimization service - how to set the price for a ride. Because the price depends on supply and demand, the price optimization service needs data from both the driver management and ride management services.\n",
    "\n",
    "The most popular styles of requests used for passing data through networks are REST (representational state transfer) and RPC (remote procedure call).\n",
    "\n",
    "## Data Passing Through Real-Time Transport\n",
    "The driver management service also needs to know the number of rides from the ride management service to know how many drivers to mobilize. It also wants to know the predicted prices from the price optimization service to use\n",
    "them as incentives for potential drivers.\n",
    "\n",
    "![Broker](./screenshots/broker.png)\n",
    "\n",
    "Technically, a database can be a broker, ach service can write data to a database and other services that need the data can read from that database. However, reads and writes are too slow for this purpose. Thus, instead we use in-memory storage.\n",
    "\n",
    "- pubsubs: publish-subscribe systems. Any service can publish to different topics in a real-time transport, and any service that subscribes to a topic can read all the events in that topic.\n",
    "- message queues: An event often has intended consumers (an event with intended consumers is called a message), and the message queue is responsible for getting the message to the right consumers."
   ],
   "id": "f969dfcd693c9e90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Batch Processing Versus Stream Processing\n",
    "\n",
    "- Batch: Data is processed in large blocks at scheduled times. Batch processing is used when you have a lot of data to process and you don’t need the results immediately. Batch processing is also used when data is collected over a period of time and then processed all at once. For features that do not change frequently.\n",
    "- Stream: Data is processed in real time. Stream processing is used when you need to process data and get results immediately. Stream processing is also used when data is generated continuously. Low latency.\n",
    "\n"
   ],
   "id": "819a3858d9215580"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
